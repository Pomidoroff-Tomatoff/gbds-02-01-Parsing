{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adeef24a",
   "metadata": {},
   "source": [
    "`GB` BigData / [Олег Гладкий](https://gb.ru/users/3837199) // домашнее задание"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20a5143",
   "metadata": {},
   "source": [
    "`262698` __Методы сбора и обработки данных из сети Интернет__:  `03`. Парсинг даных: HTML, __Beautiful-Soap__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d2b65e",
   "metadata": {},
   "source": [
    "\n",
    "## Задание 1. Beautiful-Soap. hh.ru"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88823bc8",
   "metadata": {},
   "source": [
    "Собрать информацию о вакансиях на вводимую должность с сайтов `hh.ru` и/или `Superjob` и/или `работа.ру`. Приложение должно анализировать несколько страниц сайта. Получившийся список должен содержать в себе минимум:\n",
    "* Наименование вакансии.\n",
    "* Предлагаемую зарплату (дополнительно: разносим в три поля: минимальная и максимальная и валюта. цифры преобразуем к цифрам).\n",
    "* Ссылку на саму вакансию.\n",
    "* Сайт, откуда собрана вакансия.\n",
    "\n",
    "\n",
    "По желанию можно добавить ещё параметры вакансии (например, работодателя и расположение). Структура должна быть одинаковая для вакансий со всех сайтов. Общий результат можно вывести с помощью `dataFrame` через `pandas`, сохранить в `json`, либо `csv`.\n",
    "\n",
    "Минимум — один сайт, МАКСИМУМ — все два..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7bebf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import math\n",
    "\n",
    "import platform  # информация о системе \n",
    "\n",
    "from pprint import pprint \n",
    "# import re\n",
    "# from lxml import html  # xpath"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d7c6e6",
   "metadata": {},
   "source": [
    "### Функции"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddc223e",
   "metadata": {},
   "source": [
    "__Money__, фунукция `get_money()` возвращает зарплатный словарь, полученный разбором строки от сайта:\n",
    "* минимальное значение\n",
    "* максимальное значение\n",
    "* валюту зарплаты\n",
    "\n",
    "Соглашения, для соответствия указаниям сайта и значениям словаря на примере указания сайта:\n",
    "* от 1000 р.\n",
    "    * `pay['Maney_min']` = 1000\n",
    "    * `pay['Maney_max']` = 0\n",
    "* от 1000 до 3000 р.\n",
    "    * `pay['Maney_min']` = 1000\n",
    "    * `pay['Maney_max']` = 3000 \n",
    "* до 3000 р.\n",
    "    * `pay['Maney_min']` = 0\n",
    "    * `pay['Maney_max']` = 3000\n",
    "* 1000 р.\n",
    "    * `pay['Maney_min']` = 1000\n",
    "    * `pay['Maney_max']` = 1000\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75e097da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_maney(money_range_str:str=\"\") ->dict:\n",
    "    \n",
    "    ''' Выделим цифровые значения зарплаты из строки '''\n",
    "    \n",
    "    pay = {'min': 0, 'max': 0, 'curr': ''}\n",
    "    \n",
    "    if not money_range_str:\n",
    "        return pay\n",
    "    \n",
    "    # Специальные пробельные символы необходимо \"схлопнуть\"\n",
    "    \n",
    "    special_space_symbols = {\n",
    "        \"NARROW_NO_BREAK_SPACE\": \"\\u202f\", \n",
    "        \"NO_BREAK_SPACE\": \"\\u00a0\",\n",
    "        \"TAB\":\"\\t\",\n",
    "    }\n",
    "\n",
    "    for key, space_code in special_space_symbols.items():\n",
    "        money_range_str = money_range_str.replace(space_code, \"\")\n",
    "\n",
    "    # Анализируем: \n",
    "    \n",
    "    money_words = money_range_str.split(\" \")  # Раделим строку на слова\n",
    "    i = 0\n",
    "    while money_words:\n",
    "        i += 1\n",
    "        if i  > 10:\n",
    "            print(\"Выход из бесконечного цикла\")\n",
    "            break\n",
    "      \n",
    "        if not money_words[-1].isdigit():\n",
    "            pay['curr'] = money_words[-1]\n",
    "            money_words.pop(-1)\n",
    "            continue\n",
    "\n",
    "        if money_words[0].upper() == \"от\".upper() or \\\n",
    "           money_words[0].upper() == \"from\".upper():\n",
    "            pay['min'] = int(money_words[1])\n",
    "            money_words.pop(1)\n",
    "            money_words.pop(0)\n",
    "            continue\n",
    "\n",
    "        if money_words[0].upper() == \"до\".upper():\n",
    "            pay['max'] = int(money_words[1])\n",
    "            money_words.pop(1)\n",
    "            money_words.pop(0)\n",
    "            continue\n",
    "            \n",
    "        if money_words[0] == \"-\" or money_words[0] == \"–\" or money_words[0] == \"—\" or money_words[0] == \"--\":\n",
    "            pay['max'] = int(money_words[1])\n",
    "            money_words.pop(1)\n",
    "            money_words.pop(0)\n",
    "            continue\n",
    "            \n",
    "        if money_words[0].isdigit():\n",
    "            pay['min'] = int(money_words[0])\n",
    "            money_words.pop(0)\n",
    "            continue\n",
    "        else:\n",
    "            money_words.pop(0)\n",
    "            continue\n",
    "            \n",
    "    else:\n",
    "        if not pay['min']:\n",
    "            pay['min'] = pay['max']\n",
    "        if not pay['max']:\n",
    "            pass\n",
    "            # pay['max'] = pay['min']\n",
    "        pass\n",
    "          \n",
    "    return pay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8ca2d0",
   "metadata": {},
   "source": [
    "__Soup__, фунукция `get_soup()`, возвращает струтуру `bs4.BeautifulSoup` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "730b8fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_soup(url:str=None, headers:str=None, params:str=None) -> bs(\"\", 'html.parser'):\n",
    "    \n",
    "    if not url: return None  # проверка...\n",
    "    \n",
    "    response = requests.get(url=url, headers=headers, params=params)\n",
    "    # print(response.url)\n",
    "\n",
    "    if not response.ok:\n",
    "        print(response.status_code, response.url)\n",
    "        return None\n",
    "    \n",
    "    if response.headers['Content-Type'] != 'text/html; charset=utf-8':\n",
    "        print(response.headers['Content-Type'])\n",
    "        return None\n",
    "    \n",
    "    soup = bs(response.text, 'html.parser')\n",
    "    \n",
    "    return soup "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fc6356",
   "metadata": {},
   "source": [
    "__Вакансии__: функция `get_vacancies_hh_parser` парсит вакансии с сайта `hh.ru` из полученной струтуры `soup`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7256ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vacancies_hh_parser(soup=\"\") -> list: \n",
    "    \n",
    "    ''' запрос вакансий с сайта hh.ru '''\n",
    "    \n",
    "    if not soup: return None\n",
    "    \n",
    "    cards = soup.find_all(name='div', attrs={'class': ['serp-item'], 'data-qa': True})\n",
    "    \n",
    "    if len(cards) == 0:\n",
    "        return None\n",
    "    \n",
    "    vacancies = list()\n",
    "    \n",
    "    for i, card in enumerate(cards, start=1): \n",
    "        name = card.find(name='a', attrs={'class': 'serp-item__title'}).text\n",
    "        link = card.find(name='a', attrs={'class': 'serp-item__title'}).get('href').split('?')[0]\n",
    "       \n",
    "        try:\n",
    "            comp = card.find(name='a', attrs={'class': ['bloko-link', 'bloko-link_kind-tertiary'], 'data-qa': 'vacancy-serp__vacancy-employer'}).text\n",
    "            \n",
    "        except:\n",
    "            comp = \"__AttributeError__\"\n",
    "            print(f\"AttributeError, item {i}\")\n",
    "            #comt = card.find(name='div', attrs={'class': 'vacancy-serp-item__meta-info-company'}.text)\n",
    "            \n",
    "        maney = card.find(name='span', attrs={'data-qa': 'vacancy-serp__vacancy-compensation'})\n",
    "        maney = maney.get_text(strip=False) if maney else None \n",
    "        maney = get_maney(maney) # разбор строки в список значений словаря...\n",
    "        \n",
    "        \n",
    "        vacancy = {'Name': name, 'Company': comp, 'Link': link, 'Date': request_date, 'Source': url, \\\n",
    "                   'Maney_min': maney['min'], 'Maney_max': maney['max'], 'Maney_curr': maney['curr']}\n",
    "        \n",
    "        vacancies.append(vacancy)  # type: list\n",
    "        \n",
    "    return vacancies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafce5ac",
   "metadata": {},
   "source": [
    "__Страницы__: функция `get_pages()` парсит количество страниц по данному запросу из полученной струтуры `soup`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "353ffbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pages(soup=None, item_on_page=None) ->int:\n",
    "    \n",
    "    '''Определяем количество страниц в ответе от сервера'''\n",
    "    \n",
    "    if not soup or not item_on_page: \n",
    "        print(\"get_pages() -- пустой вызов\")\n",
    "        return None\n",
    "    \n",
    "    items = soup.find(name='h1', attrs={'class': ['bloko-header-section-3'], 'data-qa': ['bloko-header-3']}).text\n",
    "    items = get_maney(items)['min']\n",
    "\n",
    "    pages = int(math.ceil(items/item_on_page))\n",
    "    \n",
    "    return pages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fb3bcd",
   "metadata": {},
   "source": [
    "### Параметры доступа к сайту"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80670cdf",
   "metadata": {},
   "source": [
    "Адрес сайта, параметры и заголовки. Агент, а так же количество позиций на страничке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd38db89",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'platform' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-1990850c4b4f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mif\u001b[0m \u001b[0mplatform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'Windows'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mwin_ver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplatform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mwin_ver\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'7'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# Windows 7 User-Agent\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mheaders\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'User-Agent'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/106.0.0.0 Safari/537.36'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mwin_ver\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'10'\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Windows 10 User-Agent\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'platform' is not defined"
     ]
    }
   ],
   "source": [
    "if platform.system() == 'Windows':\n",
    "    win_ver = platform.release()\n",
    "    if win_ver == '7': # Windows 7 User-Agent\n",
    "        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/106.0.0.0 Safari/537.36'}\n",
    "    elif win_ver == '10':  # Windows 10 User-Agent        \n",
    "        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/105.0.0.0 Safari/537.36',}\n",
    "else:\n",
    "    print(\"ВНИМАНИЕ! ЮЗЕР-АГЕНТ НЕ СООТВЕТСТВУЕТ СИСТЕМЕ\")\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/106.0.0.0 Safari/537.36'}\n",
    "\n",
    "item_on_page = 20\n",
    "url = 'https://hh.ru/search/vacancy/'\n",
    "params = {\n",
    "    'area':1,\n",
    "    'clusters':'true',\n",
    "    'enable_snippets':'true',\n",
    "    'items_on_page':item_on_page,\n",
    "    'ored_clusters':'true',\n",
    "    'search_field':'description',\n",
    "    'text':'python',\n",
    "    'order_by':'publication_time',\n",
    "    'hhtmFrom':'vacancy_search_list',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f432bc",
   "metadata": {},
   "source": [
    "## Поехали!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bb8f0e",
   "metadata": {},
   "source": [
    "Запрашиваем странички и парсим их... С небольшим таймаутом, чтобы сервер «не подумал», что мы его парсим."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0cd91616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Страница 1 обработана успешно, всего страниц 223\n",
      "Страница 2 обработана успешно, всего страниц 223\n",
      "Страница 3 обработана успешно, всего страниц 223\n",
      "Страница 4 обработана успешно, всего страниц 223\n",
      "Страница 5 обработана успешно, всего страниц 223\n",
      "Страница 6 обработана успешно, всего страниц 223\n",
      "Страница 7 обработана успешно, всего страниц 223\n",
      "Страница 8 обработана успешно, всего страниц 223\n",
      "Страница 9 обработана успешно, всего страниц 223\n",
      "Страница 10 обработана успешно, всего страниц 223\n",
      "Страница 11 обработана успешно, всего страниц 223\n",
      "Страница 12 обработана успешно, всего страниц 223\n",
      "Страница 13 обработана успешно, всего страниц 223\n",
      "Страница 14 обработана успешно, всего страниц 223\n",
      "Страница 15 обработана успешно, всего страниц 223\n",
      "Страница 16 обработана успешно, всего страниц 223\n",
      "Страница 17 обработана успешно, всего страниц 223\n",
      "Страница 18 обработана успешно, всего страниц 223\n",
      "Страница 19 обработана успешно, всего страниц 223\n",
      "Страница 20 обработана успешно, всего страниц 223\n",
      "Страница 21 обработана успешно, всего страниц 223\n",
      "Страница 22 обработана успешно, всего страниц 223\n",
      "Страница 23 обработана успешно, всего страниц 223\n",
      "Страница 24 обработана успешно, всего страниц 223\n",
      "Страница 25 обработана успешно, всего страниц 223\n",
      "Страница 26 обработана успешно, всего страниц 223\n",
      "Страница 27 обработана успешно, всего страниц 223\n",
      "Страница 28 обработана успешно, всего страниц 223\n",
      "Страница 29 обработана успешно, всего страниц 223\n",
      "Страница 30 обработана успешно, всего страниц 223\n",
      "Страница 31 обработана успешно, всего страниц 223\n",
      "Страница 32 обработана успешно, всего страниц 223\n",
      "Страница 33 обработана успешно, всего страниц 223\n",
      "Страница 34 обработана успешно, всего страниц 223\n",
      "Страница 35 обработана успешно, всего страниц 223\n",
      "Страница 36 обработана успешно, всего страниц 223\n",
      "Страница 37 обработана успешно, всего страниц 223\n",
      "Страница 38 обработана успешно, всего страниц 223\n",
      "Страница 39 обработана успешно, всего страниц 223\n",
      "Страница 40 обработана успешно, всего страниц 223\n",
      "Страница 41 обработана успешно, всего страниц 223\n",
      "Страница 42 обработана успешно, всего страниц 223\n",
      "Страница 43 обработана успешно, всего страниц 223\n",
      "Страница 44 обработана успешно, всего страниц 223\n",
      "Страница 45 обработана успешно, всего страниц 223\n",
      "Страница 46 обработана успешно, всего страниц 223\n",
      "Страница 47 обработана успешно, всего страниц 223\n",
      "Страница 48 обработана успешно, всего страниц 223\n",
      "Страница 49 обработана успешно, всего страниц 223\n",
      "Страница 50 обработана успешно, всего страниц 223\n",
      "Страница 51 обработана успешно, всего страниц 223\n",
      "Страница 52 обработана успешно, всего страниц 223\n",
      "Страница 53 обработана успешно, всего страниц 223\n",
      "Страница 54 обработана успешно, всего страниц 223\n",
      "Страница 55 обработана успешно, всего страниц 223\n",
      "Страница 56 обработана успешно, всего страниц 223\n",
      "Страница 57 обработана успешно, всего страниц 223\n",
      "Страница 58 обработана успешно, всего страниц 223\n",
      "Страница 59 обработана успешно, всего страниц 223\n",
      "Страница 60 обработана успешно, всего страниц 223\n",
      "Страница 61 обработана успешно, всего страниц 223\n",
      "Страница 62 обработана успешно, всего страниц 223\n",
      "Страница 63 обработана успешно, всего страниц 223\n",
      "Страница 64 обработана успешно, всего страниц 223\n",
      "Страница 65 обработана успешно, всего страниц 223\n",
      "Страница 66 обработана успешно, всего страниц 223\n",
      "Страница 67 обработана успешно, всего страниц 223\n",
      "Страница 68 обработана успешно, всего страниц 223\n",
      "Страница 69 обработана успешно, всего страниц 223\n",
      "Страница 70 обработана успешно, всего страниц 223\n",
      "Страница 71 обработана успешно, всего страниц 223\n",
      "Страница 72 обработана успешно, всего страниц 223\n",
      "Страница 73 обработана успешно, всего страниц 223\n",
      "Страница 74 обработана успешно, всего страниц 223\n",
      "Страница 75 обработана успешно, всего страниц 223\n",
      "Страница 76 обработана успешно, всего страниц 223\n",
      "Страница 77 обработана успешно, всего страниц 223\n",
      "Страница 78 обработана успешно, всего страниц 223\n",
      "Страница 79 обработана успешно, всего страниц 223\n",
      "Страница 80 обработана успешно, всего страниц 223\n",
      "Страница 81 обработана успешно, всего страниц 223\n",
      "Страница 82 обработана успешно, всего страниц 223\n",
      "Страница 83 обработана успешно, всего страниц 223\n",
      "Страница 84 обработана успешно, всего страниц 223\n",
      "Страница 85 обработана успешно, всего страниц 223\n",
      "Страница 86 обработана успешно, всего страниц 223\n",
      "Страница 87 обработана успешно, всего страниц 223\n",
      "Страница 88 обработана успешно, всего страниц 223\n",
      "Страница 89 обработана успешно, всего страниц 223\n",
      "Страница 90 обработана успешно, всего страниц 223\n",
      "Страница 91 обработана успешно, всего страниц 223\n",
      "Страница 92 обработана успешно, всего страниц 223\n",
      "Страница 93 обработана успешно, всего страниц 223\n",
      "Страница 94 обработана успешно, всего страниц 223\n",
      "AttributeError, item 13\n",
      "Страница 95 обработана успешно, всего страниц 223\n",
      "Страница 96 обработана успешно, всего страниц 223\n",
      "Страница 97 обработана успешно, всего страниц 223\n",
      "Страница 98 обработана успешно, всего страниц 223\n",
      "Страница 99 обработана успешно, всего страниц 223\n",
      "Страница 100 обработана успешно, всего страниц 223\n",
      "404 https://nahabino.hh.ru/search/vacancy?area=1&clusters=true&enable_snippets=true&items_on_page=20&ored_clusters=true&search_field=description&text=python&order_by=publication_time&hhtmFrom=vacancy_search_list&page=100\n",
      "Страницы выборки закончились, всего получено и обработано 100 страниц.\n",
      "Wall time: 5min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sleep_interval = 2  # задержка между запросами\n",
    "request_date = str(datetime.date.today())\n",
    "request_time = str(datetime.datetime.now().strftime(\"%H:%M\"))\n",
    "\n",
    "vacancies_dict = dict()\n",
    "vacancies = list()\n",
    "soup = \"\"\n",
    "pages = 1\n",
    "page = 0\n",
    "\n",
    "while page < pages: \n",
    "\n",
    "    params['page'] = page\n",
    "    soup = get_soup(url=url, headers=headers, params=params)\n",
    "\n",
    "    if soup:\n",
    "        vacancies_part = get_vacancies_hh_parser(soup)\n",
    "        try: \n",
    "            if len(vacancies_part) > 0 and vacancies_part != None:\n",
    "                vacancies.extend(vacancies_part)\n",
    "                # vacancies = vacancies + vacancies_part\n",
    "        except:\n",
    "            print(f\"Страница {page+1} не обработана, ошибка.\")\n",
    "                \n",
    "        time.sleep(sleep_interval)\n",
    "    else:\n",
    "        print(f\"Страницы выборки закончились, всего получено и обработано {page} страниц.\")\n",
    "        break\n",
    "\n",
    "    if page < 1:\n",
    "        pages = get_pages(soup=soup, item_on_page=item_on_page)\n",
    "        pass\n",
    "        \n",
    "    print(f\"Страница {page+1} обработана успешно, всего страниц {pages}\")\n",
    "    page += 1\n",
    "\n",
    "else:\n",
    "    print(f\"Получено {len(vacancies)} вакансий\")    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08cc82c6",
   "metadata": {},
   "source": [
    "__Запись__ данных на диск. \n",
    "Записываем все полученные данные в файл `03_hw_HTML_Beautiful-Soap_VACANCIES` на диск в `json`-формате."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3d5bacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Записываем результат на диск (пишем сразу всё, а не частично)\n",
    "\n",
    "with open('03_hw_HTML_Beautiful-Soap_VACANCIES.json', 'w') as out_f:\n",
    "    json.dump(vacancies, out_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92492d34",
   "metadata": {},
   "source": [
    "__Вид__ в формате таблицы `DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36ff9384",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер таблицы DataFrame: (2000, 8), Строк: 2000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Company</th>\n",
       "      <th>Link</th>\n",
       "      <th>Date</th>\n",
       "      <th>Source</th>\n",
       "      <th>Maney_min</th>\n",
       "      <th>Maney_max</th>\n",
       "      <th>Maney_curr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Специалист по информационной безопасности / Де...</td>\n",
       "      <td>ООО Центр корпоративных решений</td>\n",
       "      <td>https://adsrv.hh.ru/click</td>\n",
       "      <td>2022-10-10</td>\n",
       "      <td>https://hh.ru/search/vacancy/</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Старший продуктовый аналитик в команду «Поиск ...</td>\n",
       "      <td>Профи (profi.ru)</td>\n",
       "      <td>https://nahabino.hh.ru/vacancy/67773818</td>\n",
       "      <td>2022-10-10</td>\n",
       "      <td>https://hh.ru/search/vacancy/</td>\n",
       "      <td>250000</td>\n",
       "      <td>350000</td>\n",
       "      <td>руб.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Продуктовый аналитик в команду «Поиск заказов»</td>\n",
       "      <td>Профи (profi.ru)</td>\n",
       "      <td>https://nahabino.hh.ru/vacancy/70479973</td>\n",
       "      <td>2022-10-10</td>\n",
       "      <td>https://hh.ru/search/vacancy/</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Продуктовый аналитик в направление «Работодате...</td>\n",
       "      <td>ООО HeadHunter::Product Management</td>\n",
       "      <td>https://nahabino.hh.ru/vacancy/69072132</td>\n",
       "      <td>2022-10-10</td>\n",
       "      <td>https://hh.ru/search/vacancy/</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Quality Engineer</td>\n",
       "      <td>ООО HeadHunter:: IT</td>\n",
       "      <td>https://nahabino.hh.ru/vacancy/67932769</td>\n",
       "      <td>2022-10-10</td>\n",
       "      <td>https://hh.ru/search/vacancy/</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>Руководитель управления агрегированных рисков</td>\n",
       "      <td>БКС Бизнес и процессы</td>\n",
       "      <td>https://nahabino.hh.ru/vacancy/68439192</td>\n",
       "      <td>2022-10-10</td>\n",
       "      <td>https://hh.ru/search/vacancy/</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>Full-stack developer</td>\n",
       "      <td>Telecom Биржа</td>\n",
       "      <td>https://nahabino.hh.ru/vacancy/68169304</td>\n",
       "      <td>2022-10-10</td>\n",
       "      <td>https://hh.ru/search/vacancy/</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>Linux administrator/Support engineer 2L</td>\n",
       "      <td>SberTech</td>\n",
       "      <td>https://nahabino.hh.ru/vacancy/69629710</td>\n",
       "      <td>2022-10-10</td>\n",
       "      <td>https://hh.ru/search/vacancy/</td>\n",
       "      <td>150000</td>\n",
       "      <td>250000</td>\n",
       "      <td>руб.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>Эксперт платформы виртуализации серверов (Инже...</td>\n",
       "      <td>Сбер. IT</td>\n",
       "      <td>https://nahabino.hh.ru/vacancy/55566252</td>\n",
       "      <td>2022-10-10</td>\n",
       "      <td>https://hh.ru/search/vacancy/</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>DevOps (Platform V Business Apps)</td>\n",
       "      <td>SberTech</td>\n",
       "      <td>https://nahabino.hh.ru/vacancy/55873606</td>\n",
       "      <td>2022-10-10</td>\n",
       "      <td>https://hh.ru/search/vacancy/</td>\n",
       "      <td>230000</td>\n",
       "      <td>350000</td>\n",
       "      <td>руб.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Name  \\\n",
       "0     Специалист по информационной безопасности / Де...   \n",
       "1     Старший продуктовый аналитик в команду «Поиск ...   \n",
       "2        Продуктовый аналитик в команду «Поиск заказов»   \n",
       "3     Продуктовый аналитик в направление «Работодате...   \n",
       "4                                 Data Quality Engineer   \n",
       "...                                                 ...   \n",
       "1995      Руководитель управления агрегированных рисков   \n",
       "1996                               Full-stack developer   \n",
       "1997            Linux administrator/Support engineer 2L   \n",
       "1998  Эксперт платформы виртуализации серверов (Инже...   \n",
       "1999                  DevOps (Platform V Business Apps)   \n",
       "\n",
       "                                 Company  \\\n",
       "0        ООО Центр корпоративных решений   \n",
       "1                       Профи (profi.ru)   \n",
       "2                       Профи (profi.ru)   \n",
       "3     ООО HeadHunter::Product Management   \n",
       "4                    ООО HeadHunter:: IT   \n",
       "...                                  ...   \n",
       "1995               БКС Бизнес и процессы   \n",
       "1996                       Telecom Биржа   \n",
       "1997                            SberTech   \n",
       "1998                            Сбер. IT   \n",
       "1999                            SberTech   \n",
       "\n",
       "                                         Link        Date  \\\n",
       "0                   https://adsrv.hh.ru/click  2022-10-10   \n",
       "1     https://nahabino.hh.ru/vacancy/67773818  2022-10-10   \n",
       "2     https://nahabino.hh.ru/vacancy/70479973  2022-10-10   \n",
       "3     https://nahabino.hh.ru/vacancy/69072132  2022-10-10   \n",
       "4     https://nahabino.hh.ru/vacancy/67932769  2022-10-10   \n",
       "...                                       ...         ...   \n",
       "1995  https://nahabino.hh.ru/vacancy/68439192  2022-10-10   \n",
       "1996  https://nahabino.hh.ru/vacancy/68169304  2022-10-10   \n",
       "1997  https://nahabino.hh.ru/vacancy/69629710  2022-10-10   \n",
       "1998  https://nahabino.hh.ru/vacancy/55566252  2022-10-10   \n",
       "1999  https://nahabino.hh.ru/vacancy/55873606  2022-10-10   \n",
       "\n",
       "                             Source  Maney_min  Maney_max Maney_curr  \n",
       "0     https://hh.ru/search/vacancy/          0          0             \n",
       "1     https://hh.ru/search/vacancy/     250000     350000       руб.  \n",
       "2     https://hh.ru/search/vacancy/          0          0             \n",
       "3     https://hh.ru/search/vacancy/          0          0             \n",
       "4     https://hh.ru/search/vacancy/          0          0             \n",
       "...                             ...        ...        ...        ...  \n",
       "1995  https://hh.ru/search/vacancy/          0          0             \n",
       "1996  https://hh.ru/search/vacancy/          0          0             \n",
       "1997  https://hh.ru/search/vacancy/     150000     250000       руб.  \n",
       "1998  https://hh.ru/search/vacancy/          0          0             \n",
       "1999  https://hh.ru/search/vacancy/     230000     350000       руб.  \n",
       "\n",
       "[2000 rows x 8 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vacancies_DF = pd.DataFrame()\n",
    "vacancies_DF = vacancies_DF.append(vacancies, ignore_index=True)\n",
    "print(f\"Размер таблицы DataFrame: {vacancies_DF.shape}, Строк: {len(vacancies_DF)}\")\n",
    "vacancies_DF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a140533",
   "metadata": {},
   "source": [
    "<!--  -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f5c75f",
   "metadata": {},
   "source": [
    "<!--  -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01900ef",
   "metadata": {},
   "source": [
    "<!--  -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54f3788",
   "metadata": {},
   "source": [
    "__P.S.__\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edee3d5",
   "metadata": {},
   "source": [
    "* Ошибку получения атрибута `text` для названия компании `comp` победить не удалось — отложил на будущее. Но в том месте, где это происходило встречались какие-то комментарии... \n",
    "* Почему-то более 100 страниц сайт `hh.ru` не отдаёт..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02fac91",
   "metadata": {},
   "source": [
    "<!--  -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410de628",
   "metadata": {},
   "source": [
    "ZIP of code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a05520d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# инициализируем выходную таблицу\n",
    "# vacancies = pd.DataFrame( \\\n",
    "#     columns=['Name', 'Company', 'Link', 'Date', 'Source', 'Maney_min', 'Maney_max', 'Maney_curr'], \\\n",
    "#     index=[])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
