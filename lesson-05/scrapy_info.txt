GB BigData / [Олег Гладкий | Oleg Gladkiy](https://gb.ru/users/3837199) // домашнее задание
Lesson-05. Scrapy start.

Паучки:

   books.py -- шаблон основной

      scrapy crawl books -o books.json

      -- парсим краткий список учебного сайта "books.toscrape.com"
      -- только краткая инфо
      -- проходим по всем страницам кратного списка (50 стр.)
      -- не используем индивидуальные страницы книг (не "проваливаемся" по ссылке на индивидуальные страницы)



   books_pages.py -- шаблон основной, заходим в каждую книгу

      scrapy crawl books_pages -o books_pages.json

      -- парсим краткий список учебного сайта "books.toscrape.com" для получения ссылок (50 стр.)
      -- проваливаемся по полученным ссылкам (на индивидуальные страницы) 
         и получаем индивидуальные страницы используя метод scrapy.Request(...)
      -- парсим индивидуальные странцы, указывая в callback метод для их парсинга parse_book()
         > здесь напише парсер индивидуальной страницы книги



   pages.py -- шаблон "crawl": правила Rule

      scrapy crawl pages -o pages.json

      -- на каждой странице сайта получаем списко ссылок для индивидуальных страницы по каждой книге
         > списко ссылок указывается в правиле Rule
      -- проваливаемся по этому списку на индивидуальные страницы и парсим его 
         > парсер книги "parse_item" является единственным нашим методом в паучке
         > используем парсер из books_pages.py
      -- переходим на следующую страницу краткого списка и получаем ссылки
         > переход указываем в правиле Rule, в кот. ссылка на кнопку "next"
      -- ПРИМЕЧАНИЕ: 
         список книг не соответствует порядку на сайте!
